<p><link rel='stylesheet' href='../assets/css/main.css'/></p>
<p><a href="../README.html">&lt;&lt; back to main index</a></p>
<h1 id="lab-11.1-spark-structured-streaming-with-kafka">Lab 11.1: Spark
Structured Streaming with Kafka</h1>
<h3 id="overview">Overview</h3>
<p>Use Spark to process data in Kafka. This will be batch
processing.</p>
<h3 id="run-time">Run time</h3>
<p>40 mins</p>
<h2 id="step-1-inspect-spark-services">Step-1: Inspect Spark
Services</h2>
<p>Spark service should be running. Inspect it by running
<code>jps</code>. You will see a <code>master</code> and
<code>worker</code> process.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span>   jps</span></code></pre></div>
<p>output:</p>
<pre class="console"><code>...
.... master
.... worker</code></pre>
<h2 id="step-2-start-pyspark">Step-2: Start PySpark</h2>
<div class="sourceCode" id="cb3"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span>   ~/apps/spark/bin/pyspark</span></code></pre></div>
<p>In the Spark shell, try these commands</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> f <span class="op">=</span> spark.read.text(<span class="st">&#39;/etc/hosts&#39;</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> f.count()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> f.show()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;</span> exit()</span></code></pre></div>
<p>You might see output like this:</p>
<pre class="console"><code>+--------------------+
|               value|
+--------------------+
| 127.0.0.1     localhost|
|::1    localhost ip6...|
|fe00::0        ip6-localnet|
|ff00::0        ip6-mcast...|
|ff02::1        ip6-allnodes|
|ff02::2        ip6-allro...|
|10.10.0.2      2282d19...|
+--------------------+</code></pre>
<h2 id="step-3-create-clickstream-topic">Step-3: Create Clickstream
Topic</h2>
<p>If you don’t have the topic, create it as follows</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span>   ~/apps/kafka/bin/kafka-topics.sh  <span class="at">--bootstrap-server</span> localhost:9092   <span class="dt">\</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">--create</span> <span class="at">--topic</span> test <span class="at">--replication-factor</span> 1  <span class="at">--partitions</span> 10</span></code></pre></div>
<h2 id="step-4-install-kafka-python-library">Step-4: Install Kafka
Python Library</h2>
<div class="sourceCode" id="cb7"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span>   pip install confluent_kafka</span></code></pre></div>
<h2 id="step-5-generate-clickstream-data">Step-5: Generate Clickstream
data</h2>
<p>Open a terminal and run the python producer:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span>   cd  ~/kafka-labs/python</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span>   python producer-clickstream.py</span></code></pre></div>
<p>This will populate clickstream topic</p>
<h2 id="step-6-inspect-spark-consumer-code">Step-6: Inspect Spark
Consumer Code</h2>
<p>Inspect file: <code>python/spark-consumer-batch.py</code></p>
<p>We will work through TODO items in this file</p>
<h2 id="step-7-run-spark-consumer">Step-7: Run Spark Consumer</h2>
<p>Open a terminal and execute these commands:</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span>   cd  ~/kafka-labs/python</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span>  ~/apps/spark/bin/spark-submit  <span class="at">--master</span> local[2] <span class="dt">\</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">--driver-class-path</span> .  <span class="dt">\</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">--packages</span> org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1 <span class="dt">\</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    spark-consumer-batch.py</span></code></pre></div>
<p>This will initialize Spark session and connect to Kafka. You will
output like following</p>
<pre class="console"><code>root
 |-- key: string (nullable = true)
 |-- value: string (nullable = true)
 |-- topic: string (nullable = true)
 |-- partition: integer (nullable = true)
 |-- offset: long (nullable = true)
 |-- timestamp: timestamp (nullable = true)</code></pre>
<p><strong>ACTION: Observe how Spark reads from Kafka and the data
types</strong></p>
<h3 id="troubleshoting-tips">Troubleshoting Tips</h3>
<p>I have noticed in some instances, downloading dependencies will fail.
If that happens, try this:</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># clean up ivy caches</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span>   rm <span class="at">-rf</span>    ~/.ivy2/cache   ~/.ivy2/jars</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># If the above doesn&#39;t work, try cleaning up local mvn repository</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># $   rm -rf  ~/.m2/repository</span></span></code></pre></div>
<p>And then re-run spark application.</p>
<p>References</p>
<ul>
<li><a
href="https://github.com/databricks/spark-deep-learning/issues/190#issuecomment-479999455">issue
#190</a></li>
</ul>
<h2 id="step-8-todo-1---go-through-all-kafka-data">Step-8: TODO-1 - Go
through all Kafka Data</h2>
<p>Here is code process entire Kafka data</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code for </span><span class="al">TODO</span><span class="co">-1</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;total count: &quot;</span>, df.count())</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>df.show()</span></code></pre></div>
<p><strong>ACTION: Fill this in for TODO-1 placehold</strong></p>
<p><strong>ACTION: Run the code again (See Step-4 for run
command)</strong></p>
<p><strong>ACTION: Observe the output. You may see output as
follows:</strong></p>
<pre class="console"><code>+------------+--------------------+-----------+---------+------+--------------------+
|         key|               value|      topic|partition|offset|           timestamp|
+------------+--------------------+-----------+---------+------+--------------------+
|facebook.com|{&quot;timestamp&quot;: 164...|clickstream|        9|  1988|2022-01-22 04:37:...|
|facebook.com|{&quot;timestamp&quot;: 164...|clickstream|        9|  1989|2022-01-22 04:37:...|
|facebook.com|{&quot;timestamp&quot;: 164...|clickstream|        9|  1990|2022-01-22 04:37:...|
+------------+--------------------+-----------+---------+------+--------------------+</code></pre>
<h2 id="step-9-todo-2---extract-kafka-data-into-dataframes">Step-9:
TODO-2 - Extract Kafka Data into Dataframes</h2>
<p>Now let’s extract JSON data into Spark dataframe, so we can process
it easily.</p>
<p>Use the code below</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code for </span><span class="al">TODO</span><span class="co">-2</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># first we need a schema</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>schema <span class="op">=</span> StructType(</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    [</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>        StructField(<span class="st">&#39;timestamp&#39;</span>, StringType(), <span class="va">True</span>),</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        StructField(<span class="st">&#39;ip&#39;</span>, StringType(), <span class="va">True</span>),</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        StructField(<span class="st">&#39;user&#39;</span>, StringType(), <span class="va">True</span>),</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>        StructField(<span class="st">&#39;action&#39;</span>, StringType(), <span class="va">True</span>),</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        StructField(<span class="st">&#39;domain&#39;</span>, StringType(), <span class="va">True</span>),</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        StructField(<span class="st">&#39;campaign&#39;</span>, StringType(), <span class="va">True</span>),</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        StructField(<span class="st">&#39;cost&#39;</span>, IntegerType(), <span class="va">True</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co"># extract value from JSON string and populate into another df</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df.withColumn(<span class="st">&quot;value&quot;</span>, from_json(<span class="st">&quot;value&quot;</span>, schema))<span class="op">\</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    .select(col(<span class="st">&#39;key&#39;</span>), col(<span class="st">&#39;value.*&#39;</span>))</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>df2.printSchema()</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>df2.sample(<span class="fl">0.1</span>).show()</span></code></pre></div>
<p><strong>ACTION: Fill this in for TODO-2 placehold</strong></p>
<p><strong>ACTION: Run the code again (See Step-4 for run
command)</strong></p>
<p><strong>ACTION: Observe the output. You may see output as
follows:</strong></p>
<pre class="console"><code>+------------+-------------+---------+-------+-------+------------+-----------+----+
|         key|    timestamp|       ip|   user| action|      domain|   campaign|cost|
+------------+-------------+---------+-------+-------+------------+-----------+----+
|facebook.com|1642826798006|  1.4.4.3|user-33|blocked|facebook.com|campaign-59|  93|
|   gmail.com|1642826796603|  1.2.8.1|user-18| viewed|   gmail.com|campaign-17|  66|
|   gmail.com|1642826796803|  3.1.2.7|user-67| viewed|   gmail.com|campaign-88|  78|
+------------+-------------+---------+-------+-------+------------+-----------+----+</code></pre>
<h2 id="step-10-todo-3-run-a-spark-sql-query-on-the-data">Step-10:
TODO-3 : Run a Spark-SQL Query on the Data</h2>
<p>we are going to run a SQL query on Kafka data! How cool is that?</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code for </span><span class="al">TODO</span><span class="co">-3</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s do a SQL query on Kafka data!</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>df2.createOrReplaceTempView(<span class="st">&quot;clickstream_view&quot;</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate avg spend per domain</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>sql_str <span class="op">=</span> <span class="st">&quot;&quot;&quot;</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT domain, count(*) as impressions, MIN(cost), AVG(cost), MAX(cost)</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="st">FROM clickstream_view</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="st">GROUP BY domain</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;&quot;&quot;</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>spark.sql(sql_str).show()</span></code></pre></div>
<p><strong>ACTION: Fill in the code</strong></p>
<p><strong>ACTION: run the file</strong></p>
<p><strong>ACTION: and observe the results</strong></p>
<pre class="console"><code>+------------+-----------+---------+------------------+---------+
|      domain|impressions|min(cost)|         avg(cost)|max(cost)|
+------------+-----------+---------+------------------+---------+
| youtube.com|       2579|        1|50.037999224505626|      100|
|   gmail.com|       2669|        1|51.293368302735104|      100|
|facebook.com|       2571|        1|50.560093348891485|      100|
| twitter.com|       2663|        1| 50.78708223807735|      100|
|linkedin.com|       2682|        1|51.319910514541384|      100|
+------------+-----------+---------+------------------+---------+</code></pre>
<h2 id="step-11-todo-4-run-another-spark-sql-query">Step-11: TODO-4: Run
another Spark SQL query</h2>
<p>Let’s continue with Spark SQL and do another query. This time, we are
going to calculte the ad performance - views / clicks / blocks - per
domain.</p>
<p>Here is the code:</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code for </span><span class="al">TODO</span><span class="co">-4</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># count clicks/views/blocks</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>sql_str <span class="op">=</span> <span class="st">&quot;&quot;&quot;</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="st">SELECT domain, action, COUNT(action)</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="st">FROM clickstream_view</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="st">GROUP BY ???, ???</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="st">ORDER BY ???</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;&quot;&quot;</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>spark.sql(sql_str).show()</span></code></pre></div>
<p><strong>ACTION: Fill in the code</strong></p>
<p><strong>ACTION: run the file</strong></p>
<p><strong>ACTION: and observe the results</strong></p>
<pre class="console"><code>+------------+-------+-------------+
|      domain| action|count(action)|
+------------+-------+-------------+
|facebook.com|blocked|          839|
|facebook.com|clicked|          878|
|facebook.com| viewed|          854|
|   gmail.com|blocked|          919|
|   gmail.com|clicked|          876|
|   gmail.com| viewed|          874|
|linkedin.com|blocked|          869|
|linkedin.com|clicked|          951|
|linkedin.com| viewed|          862|
| twitter.com|blocked|          889|
| twitter.com|clicked|          892|
| twitter.com| viewed|          882|
| youtube.com|blocked|          822|
| youtube.com|clicked|          914|
| youtube.com| viewed|          843|
+------------+-------+-------------+</code></pre>
<h2
id="step-12-bonus-lab-tweak-the-sql-to-produce-a-result-table-like-this">Step-12:
Bonus Lab: Tweak the SQL to Produce a Result Table like this</h2>
<pre class="console"><code>| domain       | views | clicks | blocks |   |
|--------------|-------|--------|--------|---|
| facebook.com | 5     | 7      | 12     |   |
| twitter.com  | 10    | 5      | 9      |   |
| youtube.com  | 15    | 4      | 10     |   |</code></pre>
